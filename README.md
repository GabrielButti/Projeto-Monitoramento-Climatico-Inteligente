# ğŸ“Š Monitoramento ClimÃ¡tico Inteligente â€” Projeto End-to-End

## ğŸ“Œ DescriÃ§Ã£o
Pipeline **end-to-end** para coleta, processamento, prediÃ§Ã£o e visualizaÃ§Ã£o de dados climÃ¡ticos. Coleta via Open-Meteo, persistÃªncia em **PostgreSQL**, processamento com **PySpark**, modelo **Prophet** e dashboard **Streamlit**.

## ğŸ¯ Objetivos da AnÃ¡lise
- **Coleta de dados** via API Open-Meteo
- **Armazenamento** em PostgreSQL
- **Processamento** e agregaÃ§Ã£o de dados histÃ³ricos com PySpark
- **Modelagem** usando Prophet para previsÃ£o de temperatura
- **Dashboard interativo** em Streamlit para explorar histÃ³rico e previsÃµes

## â“ Perguntas de NegÃ³cio
- Qual a previsÃ£o de temperatura para as prÃ³ximas 24 horas na localizaÃ§Ã£o X (ex.: SÃ£o Paulo)?
- Quais padrÃµes diÃ¡rios/semanais sÃ£o observÃ¡veis (sazonalidade, picos)?
- Quais sÃ£o as estatÃ­sticas agregadas relevantes (mÃ©dia horÃ¡ria, mÃ¡ximas diÃ¡rias, extremos)?
- Qual a acurÃ¡cia das previsÃµes (RMSE, MAE) para horizontes curtos (24h)?
- Como automatizar a coleta e garantir dados contÃ­nuos (pipeline confiÃ¡vel)?
- Qual o impacto de eventos extremos (picos de temperatura) para operaÃ§Ãµes (logÃ­stica/energia)?


## ğŸ—‚ï¸ Estrutura do Projeto

```
projeto-monitoramento-climatico-inteligente/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/media_diaria          # Dados gerados pelo Pyspark
â”‚   â””â”€â”€ processed/media_horaria         # Dados gerados pelo Pyspark
â”œâ”€â”€ notebooks/  
â”‚   â””â”€â”€ analise_modelo.ipynb            # VisualizaÃ§Ã£o de Resultados do Modelo
â”œâ”€â”€ src/    
â”‚   â”œâ”€â”€ coleta_dados.py                 # Coleta e GravaÃ§Ã£o no Postgres
â”‚   â”œâ”€â”€ processamento_pyspark.py        # AgregaÃ§Ãµes com PySpark
â”‚   â”œâ”€â”€ trainamento_modelo.py           # Treinamento Prophet e Salvamento Modelo
â”‚   â””â”€â”€ app.py                          # Streamlit Dashboard
â”œâ”€â”€ models/ 
â”‚   â””â”€â”€ previsao_diaria.pkl             # Modelo para PrevisÃ£o DiÃ¡ria
â”‚   â””â”€â”€ previsao_horaria.pkl            # Modelo para PrevisÃ£o HorÃ¡ria
â”œâ”€â”€ assets                              # GrÃ¡ficos Gerados
â”œâ”€â”€ .gitignore                          # ExcessÃ£o git
â”œâ”€â”€ requirements.txt                    # DependÃªncias do projeto 
â””â”€â”€ README.md                           # DocumentaÃ§Ã£o do projeto
```

## ğŸ”§ Ferramentas Utilizadas
- **Python 3.14+**
- **Pandas / Numpy / Unidecode** â€“ ManipulaÃ§Ã£o de dados
- **Pyspark** - Processamento de Dados
- **Requests / SQLAlchemy** - Coleta e ETL
- **Scikit-learn / Prophet** â€“ Modelagem preditiva
- **Joblib** â€“ Salvamento do modelo
- **Matplotlib / Seaborn / Plotly / Streamlit** â€“ VisualizaÃ§Ã£o de dados
- **dotenv** - Gerenciamento de Credenciais
- **Jupyter Notebook** â€“ DocumentaÃ§Ã£o da anÃ¡lise
---

## ğŸ“Š Principais Insights


### Qual Ã© a previsÃ£o de temperatura para as prÃ³ximas 24 horas?

- O dashboard apresenta uma previsÃ£o horÃ¡ria detalhada para as prÃ³ximas **24h**, gerada pelo modelo Prophet, incluindo **intervalo de confianÃ§a** (yhat_lower, yhat_upper), permitindo anÃ¡lise de cenÃ¡rios otimista, central e pessimista.


![PrevisÃ£o Tempo](assets/previsao_temp.png)

---

### Quais padrÃµes diÃ¡rios sÃ£o observados?
- A decomposiÃ§Ã£o da sÃ©rie temporal e as agregaÃ§Ãµes PySpark evidenciaram uma forte **sazonalidade diÃ¡ria**, com temperatura mÃ­nima tipicamente entre **4h e 6h** e mÃ¡xima entre **13h e 15h**, padrÃ£o consistente ao longo do histÃ³rico.

![Forecast](assets/forecast.png) 

---

### Quais sÃ£o as mÃ©dias e extremos de temperatura?
- As mÃ©tricas (mÃ©dia, mÃ­nimo, mÃ¡ximo) sÃ£o calculadas automaticamente em nÃ­vel horÃ¡rio e diÃ¡rio, permitindo anÃ¡lise de variabilidade climÃ¡tica e acompanhamento de extremos histÃ³ricos via dashboard interativo.

---

### Como garantir que os dados fiquem atualizados?
- O pipeline de coleta (coleta_dados.py) foi projetado para execuÃ§Ã£o periÃ³dica via cron ou orquestradores como Airflow, garantindo ingestÃ£o contÃ­nua, deduplicaÃ§Ã£o de registros (chave primÃ¡ria por timestamp) e atualizaÃ§Ã£o incremental da base de dados.

---

### QuÃ£o preciso Ã© o modelo?
- A avaliaÃ§Ã£o com backtesting (janela de validaÃ§Ã£o temporal) resultou em RMSE mÃ©dio < 1.5 Â°C para horizontes de 24h, com boa aderÃªncia aos padrÃµes sazonais. O modelo Ã© facilmente re-treinado conforme novos dados sÃ£o incorporados, mitigando model drift.

---

## PrÃ³ximos Passos
- **Agendar** coleta automÃ¡tica (cron ou Airflow).
- **Implementar** monitoramento de performance do modelo (MAE/RMSE em tempo real).
- **Expandir** para mÃºltiplas localizaÃ§Ãµes (multi-cidades).
- **Incluir** variÃ¡veis adicionais (precipitaÃ§Ã£o, vento, umidade) e prever eventos extremos.
- **Integrar** notificaÃ§Ãµes (Slack/Email) para alertar sobre picos de temperatura.

## ğŸ“Œ Como Reproduzir
```bash
git clone https://github.com/GabrielButti/Projeto-Monitoramento-Climatico-Inteligente.git
cd Projeto-Monitoramento-Climatico-Inteligente
python -m venv venv
venv\Scripts\activate  # (Windows)
pip install -r requirements.txt

Crie um arquivo .env com:

PG_USER=postgres
PG_PASS=postgres
PG_HOST=localhost
PG_PORT=5432
PG_DB=climate_db

python src/coleta_dados.py
spark-submit --jars /path/to/postgresql-42.5.0.jar src/processamento_pyspark.py
python src/trainamento_modelo.py
jupyter notebook notebooks/analise_modelo.ipynb
streamlit run src/app.py
